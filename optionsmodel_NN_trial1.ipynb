{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8f7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "options_df = pd.read_csv(\"options_cleaned.csv\")\n",
    "\n",
    "# options_df.sample(frac=1, random_state=43)\n",
    "full_options_df = pd.read_csv(\"options_withriskfreerates_andDeltaT.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52fae1",
   "metadata": {},
   "source": [
    "Need to prepare the train, validation/dev and test sets. In this first trial, I will use a 70%/20%/10% split\n",
    "\n",
    "I will also perform this split individually for each stock ticker, in order to have equal portions from each stock ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af5a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"AAPL\",\"NVDA\",\"TSLA\",\"AMD\",\"AMZN\",\"MSFT\",\"META\",\"SPY\"]\n",
    "\n",
    "train_list = []\n",
    "dev_list = []\n",
    "test_list = []\n",
    "\n",
    "for ticker in tickers:\n",
    "\n",
    "    df = options_df[full_options_df[\"stockTicker\"] == ticker]\n",
    "\n",
    "    train, dev, test = np.split(df.sample(frac=1,random_state=42), \n",
    "                       [int(0.7*len(df)), int(.9*len(df))])\n",
    "    \n",
    "    train_list.append(train)\n",
    "    dev_list.append(dev)\n",
    "    test_list.append(test)\n",
    "\n",
    "train_df = pd.concat(train_list, ignore_index=True)\n",
    "dev_df = pd.concat(dev_list, ignore_index=True)\n",
    "test_df = pd.concat(test_list, ignore_index=True)\n",
    "\n",
    "target_col = \"lastPrice\"\n",
    "\n",
    "Y_train = train_df[[target_col]]\n",
    "X_train = train_df.drop(columns=[target_col])\n",
    "\n",
    "Y_dev = dev_df[[target_col]]\n",
    "X_dev = dev_df.drop(columns=[target_col])\n",
    "\n",
    "Y_test = test_df[[target_col]]\n",
    "X_test = test_df.drop(columns=[target_col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362ed5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_dev_scaled = scaler.transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3034b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit Input layer\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0546640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)  \n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4903d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float4_e2m1fn'\n",
      "Epoch 1/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 260231.8438 - mae: 98.5948 - val_loss: 12581.5566 - val_mae: 67.4360\n",
      "Epoch 2/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 24915.9883 - mae: 71.3721 - val_loss: 28224.6055 - val_mae: 77.3034\n",
      "Epoch 3/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 41376.5859 - mae: 76.0322 - val_loss: 11755.7109 - val_mae: 66.0819\n",
      "Epoch 4/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 12305.9287 - mae: 66.4401 - val_loss: 11338.2383 - val_mae: 66.0957\n",
      "Epoch 5/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 24699.3594 - mae: 67.2912 - val_loss: 25657.2988 - val_mae: 76.3230\n",
      "Epoch 6/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 15609.7539 - mae: 67.1278 - val_loss: 10519.0039 - val_mae: 60.9594\n",
      "Epoch 7/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 10689.2119 - mae: 60.8965 - val_loss: 10130.7178 - val_mae: 59.6834\n",
      "Epoch 8/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 11745.7686 - mae: 60.0359 - val_loss: 9904.3848 - val_mae: 58.2345\n",
      "Epoch 9/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 13288.7881 - mae: 60.9146 - val_loss: 9239.3984 - val_mae: 55.0297\n",
      "Epoch 10/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9570.5303 - mae: 55.7313 - val_loss: 8966.6416 - val_mae: 53.6594\n",
      "Epoch 11/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8760.5430 - mae: 53.4013 - val_loss: 10907.0518 - val_mae: 55.3991\n",
      "Epoch 12/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9885.8428 - mae: 53.9716 - val_loss: 8126.7090 - val_mae: 49.7746\n",
      "Epoch 13/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8472.3037 - mae: 51.7313 - val_loss: 8113.6436 - val_mae: 49.9194\n",
      "Epoch 14/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 7868.0337 - mae: 50.0774 - val_loss: 7676.3384 - val_mae: 47.5580\n",
      "Epoch 15/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 14493.3682 - mae: 51.3754 - val_loss: 30079.7695 - val_mae: 57.0529\n",
      "Epoch 16/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 18255.7559 - mae: 51.9040 - val_loss: 7295.6899 - val_mae: 45.2111\n",
      "Epoch 17/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6887.8140 - mae: 44.4728 - val_loss: 7930.8501 - val_mae: 44.3868\n",
      "Epoch 18/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 7126.0054 - mae: 43.8087 - val_loss: 6886.4053 - val_mae: 44.7930\n",
      "Epoch 19/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6762.9448 - mae: 42.7371 - val_loss: 6449.0034 - val_mae: 41.1370\n",
      "Epoch 20/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6475.0352 - mae: 41.4955 - val_loss: 6258.8823 - val_mae: 38.8360\n",
      "Epoch 21/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6419.8862 - mae: 39.8235 - val_loss: 5627.2549 - val_mae: 37.2754\n",
      "Epoch 22/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5481.4507 - mae: 36.4015 - val_loss: 5664.0757 - val_mae: 35.4158\n",
      "Epoch 23/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 5221.6450 - mae: 34.8584 - val_loss: 5745.4019 - val_mae: 37.4947\n",
      "Epoch 24/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8192.3545 - mae: 37.0259 - val_loss: 5210.8042 - val_mae: 33.5745\n",
      "Epoch 25/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 6873.2427 - mae: 35.5056 - val_loss: 18270.4922 - val_mae: 38.6449\n",
      "Epoch 26/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 8529.5371 - mae: 33.3624 - val_loss: 5118.6577 - val_mae: 33.6501\n",
      "Epoch 27/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4692.0122 - mae: 30.7288 - val_loss: 4432.7114 - val_mae: 28.6023\n",
      "Epoch 28/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4255.0723 - mae: 29.4536 - val_loss: 4256.1733 - val_mae: 29.7320\n",
      "Epoch 29/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 4292.4336 - mae: 28.8164 - val_loss: 4058.8267 - val_mae: 27.0649\n",
      "Epoch 30/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4073.2988 - mae: 28.5352 - val_loss: 3936.9856 - val_mae: 28.6124\n",
      "Epoch 31/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3749.7639 - mae: 27.0750 - val_loss: 4169.8540 - val_mae: 30.9664\n",
      "Epoch 32/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3721.0408 - mae: 27.7320 - val_loss: 3430.0952 - val_mae: 26.4744\n",
      "Epoch 33/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3345.8584 - mae: 26.2847 - val_loss: 3375.0330 - val_mae: 25.7266\n",
      "Epoch 34/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 3183.6304 - mae: 24.7291 - val_loss: 3111.0842 - val_mae: 25.7466\n",
      "Epoch 35/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 3078.1826 - mae: 25.4037 - val_loss: 3024.7786 - val_mae: 23.4515\n",
      "Epoch 36/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2709.5444 - mae: 23.8564 - val_loss: 2464.4675 - val_mae: 21.3746\n",
      "Epoch 37/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 2419.9895 - mae: 22.4725 - val_loss: 1823.5010 - val_mae: 20.3008\n",
      "Epoch 38/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1912.2180 - mae: 20.9713 - val_loss: 2255.6470 - val_mae: 23.9480\n",
      "Epoch 39/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2265.2446 - mae: 22.0836 - val_loss: 1335.9744 - val_mae: 18.8606\n",
      "Epoch 40/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1457.3079 - mae: 18.3221 - val_loss: 1160.2700 - val_mae: 17.6750\n",
      "Epoch 41/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1425.6285 - mae: 18.1816 - val_loss: 1874.5237 - val_mae: 22.4557\n",
      "Epoch 42/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1915.0770 - mae: 20.4632 - val_loss: 1446.5013 - val_mae: 18.8656\n",
      "Epoch 43/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1523.1198 - mae: 19.6571 - val_loss: 1060.3362 - val_mae: 18.7960\n",
      "Epoch 44/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1173.2032 - mae: 17.4026 - val_loss: 1127.8585 - val_mae: 18.0761\n",
      "Epoch 45/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1057.6157 - mae: 16.3072 - val_loss: 787.4434 - val_mae: 14.7969\n",
      "Epoch 46/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1343.5439 - mae: 18.8228 - val_loss: 740.6013 - val_mae: 14.0831\n",
      "Epoch 47/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 902.1565 - mae: 15.1882 - val_loss: 1174.6135 - val_mae: 19.8947\n",
      "Epoch 48/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 906.5869 - mae: 14.9875 - val_loss: 593.0312 - val_mae: 12.4162\n",
      "Epoch 49/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 740.1164 - mae: 13.7747 - val_loss: 797.3546 - val_mae: 16.7957\n",
      "Epoch 50/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 959.1127 - mae: 14.9027 - val_loss: 646.0897 - val_mae: 13.3773\n",
      "Epoch 51/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 869.8072 - mae: 15.8912 - val_loss: 480.3351 - val_mae: 12.2622\n",
      "Epoch 52/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1219.0708 - mae: 17.2753 - val_loss: 598.7590 - val_mae: 14.0422\n",
      "Epoch 53/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 834.2994 - mae: 14.7143 - val_loss: 570.6180 - val_mae: 13.5917\n",
      "Epoch 54/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 618.3421 - mae: 13.7078 - val_loss: 1004.6816 - val_mae: 20.1083\n",
      "Epoch 55/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 667.7047 - mae: 14.1957 - val_loss: 465.8733 - val_mae: 14.5482\n",
      "Epoch 56/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 706.5908 - mae: 14.1265 - val_loss: 576.7989 - val_mae: 13.0902\n",
      "Epoch 57/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 708.1176 - mae: 13.4784 - val_loss: 562.2301 - val_mae: 15.9155\n",
      "Epoch 58/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 521.3568 - mae: 12.2866 - val_loss: 361.6869 - val_mae: 10.7363\n",
      "Epoch 59/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2277.5479 - mae: 14.7461 - val_loss: 421.3226 - val_mae: 11.7569\n",
      "Epoch 60/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 560.0050 - mae: 12.7236 - val_loss: 372.2773 - val_mae: 11.7697\n",
      "Epoch 61/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 527.6260 - mae: 12.4020 - val_loss: 501.3706 - val_mae: 12.9961\n",
      "Epoch 62/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 895.8907 - mae: 14.9392 - val_loss: 348.7774 - val_mae: 11.5491\n",
      "Epoch 63/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 573.8303 - mae: 13.3254 - val_loss: 577.5940 - val_mae: 14.4427\n",
      "Epoch 64/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - loss: 591.6740 - mae: 13.0056 - val_loss: 591.1343 - val_mae: 14.8313\n",
      "Epoch 65/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 657.3984 - mae: 13.5561 - val_loss: 273.6207 - val_mae: 10.2283\n",
      "Epoch 66/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 545.1146 - mae: 12.4716 - val_loss: 318.5137 - val_mae: 9.9767\n",
      "Epoch 67/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 580.1428 - mae: 13.3327 - val_loss: 440.0926 - val_mae: 12.4874\n",
      "Epoch 68/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 617.6382 - mae: 13.7998 - val_loss: 819.9800 - val_mae: 14.6626\n",
      "Epoch 69/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 569.1644 - mae: 12.9214 - val_loss: 292.2775 - val_mae: 10.1721\n",
      "Epoch 70/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 388.8380 - mae: 11.5714 - val_loss: 300.2259 - val_mae: 9.6528\n",
      "Epoch 71/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 583.0964 - mae: 12.6699 - val_loss: 519.4771 - val_mae: 13.0291\n",
      "Epoch 72/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 670.2699 - mae: 13.0849 - val_loss: 422.8633 - val_mae: 12.8791\n",
      "Epoch 73/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 736.6006 - mae: 13.4092 - val_loss: 351.6729 - val_mae: 11.2731\n",
      "Epoch 74/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 586.3876 - mae: 11.9210 - val_loss: 311.1718 - val_mae: 10.6426\n",
      "Epoch 75/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 484.0656 - mae: 12.2730 - val_loss: 273.8614 - val_mae: 9.5844\n",
      "Epoch 76/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 354.1234 - mae: 11.1251 - val_loss: 865.7217 - val_mae: 15.5062\n",
      "Epoch 77/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 779.1470 - mae: 14.2663 - val_loss: 260.1342 - val_mae: 10.3159\n",
      "Epoch 78/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 405.9312 - mae: 11.4227 - val_loss: 537.6937 - val_mae: 14.0811\n",
      "Epoch 79/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 415.6108 - mae: 11.6897 - val_loss: 344.8279 - val_mae: 10.0979\n",
      "Epoch 80/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 574.3738 - mae: 12.2665 - val_loss: 236.1026 - val_mae: 9.2400\n",
      "Epoch 81/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 453.1761 - mae: 11.1282 - val_loss: 545.0618 - val_mae: 13.1571\n",
      "Epoch 82/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 443.9798 - mae: 12.2619 - val_loss: 234.1238 - val_mae: 10.0103\n",
      "Epoch 83/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 305.4637 - mae: 10.0399 - val_loss: 356.5280 - val_mae: 12.0353\n",
      "Epoch 84/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 406.8977 - mae: 11.2381 - val_loss: 233.9642 - val_mae: 9.7826\n",
      "Epoch 85/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 340.0298 - mae: 10.7141 - val_loss: 324.7797 - val_mae: 11.4580\n",
      "Epoch 86/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 366.1190 - mae: 10.9983 - val_loss: 515.2789 - val_mae: 12.9748\n",
      "Epoch 87/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 397.3743 - mae: 11.8031 - val_loss: 324.2231 - val_mae: 9.4939\n",
      "Epoch 88/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 432.9160 - mae: 11.5906 - val_loss: 239.6250 - val_mae: 10.0292\n",
      "Epoch 89/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 351.7108 - mae: 11.0400 - val_loss: 218.7193 - val_mae: 9.2508\n",
      "Epoch 90/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 392.4512 - mae: 11.0067 - val_loss: 589.9600 - val_mae: 12.5424\n",
      "Epoch 91/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 471.7021 - mae: 11.5463 - val_loss: 1052.3948 - val_mae: 18.2893\n",
      "Epoch 92/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 339.8881 - mae: 10.8379 - val_loss: 192.4895 - val_mae: 8.7990\n",
      "Epoch 93/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 351.7587 - mae: 10.1046 - val_loss: 970.0517 - val_mae: 17.9032\n",
      "Epoch 94/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 359.3067 - mae: 11.0669 - val_loss: 437.7753 - val_mae: 12.3680\n",
      "Epoch 95/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 367.0524 - mae: 11.4993 - val_loss: 264.6863 - val_mae: 10.6158\n",
      "Epoch 96/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 278.1841 - mae: 9.8212 - val_loss: 924.4510 - val_mae: 20.1192\n",
      "Epoch 97/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 594.4064 - mae: 13.3897 - val_loss: 360.3231 - val_mae: 11.9228\n",
      "Epoch 98/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 333.4989 - mae: 10.6993 - val_loss: 466.4154 - val_mae: 13.9154\n",
      "Epoch 99/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 649.3869 - mae: 12.3435 - val_loss: 294.7973 - val_mae: 10.3738\n",
      "Epoch 100/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 290.0315 - mae: 10.3313 - val_loss: 309.2389 - val_mae: 10.3376\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_dev, Y_dev),\n",
    "    epochs=100,              # Start with a small number, like 50\n",
    "    batch_size=32,          # Common choice\n",
    "    verbose=1               # Shows progress per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e5d25da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b3a0944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0005)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.learning_rate.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87544f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1474431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.507769584655762, 13.244246482849121)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"mae\"][-1],history.history[\"val_mae\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41790b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BlackScholesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50e343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price = options_df[\"stockClosePrice\"]\n",
    "strike_price = options_df[\"strike\"]\n",
    "riskfree_rate = options_df[\"riskfree_rate\"]\n",
    "time_to_expiry = options_df[\"deltaT_years\"]\n",
    "volatility = options_df[\"impliedVolatility\"]\n",
    "isCall = options_df[\"isCall\"]\n",
    "\n",
    "price_BS = np.zeros_like(stock_price)\n",
    "\n",
    "for i in range(len(options_df)):\n",
    "    price_BS[i] = BlackScholesModel(stock_price[i],strike_price[i],riskfree_rate[i],time_to_expiry[i],volatility[i],isCall[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208b3be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(29.591169294508173)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_BS = np.mean(np.abs(price_BS - options_df[\"lastPrice\"]))\n",
    "\n",
    "mae_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea4facd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(80.99049724896837), np.float64(135.43975112824418))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_df[\"lastPrice\"].mean(), options_df[\"lastPrice\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f67d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune number of layers (1 to 3)\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=256, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='linear'))  # output layer for regression\n",
    "\n",
    "    # Tune optimizer\n",
    "    optimizer = hp.Choice(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=getattr(keras.optimizers, optimizer.capitalize())(learning_rate=learning_rate),\n",
    "        loss=\"mae\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fda0064d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_mae\",\n",
    "    max_trials=10,              # Try 10 different hyperparameter combinations\n",
    "    executions_per_trial=1,     # How many times to train each model\n",
    "    directory=\"kt_tuner\",\n",
    "    project_name=\"option_price_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a52aafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 00s]\n",
      "\n",
      "Best val_mae So Far: 7.587751388549805\n",
      "Total elapsed time: 00h 09m 51s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "tuner.search(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_dev, Y_dev),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1445b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 32\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.0009388837297496945\n",
      "units_1: 128\n",
      "units_2: 64\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.1134 - mae: 9.1134\n",
      "Test MAE: 7.897063255310059\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for param in best_hp.values:\n",
    "    print(f\"{param}: {best_hp.get(param)}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss, test_mae = best_model.evaluate(X_test, Y_test)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188d9e1",
   "metadata": {},
   "source": [
    "After tuning and finding the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb5fecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"best_model_from_tuner.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd2d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit Input layer\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5995019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0009)  \n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "884c6836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 615095.3125 - mae: 116.2965 - val_loss: 13190.6465 - val_mae: 66.7566\n",
      "Epoch 2/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 20778.9297 - mae: 73.5029 - val_loss: 76294.9453 - val_mae: 98.9629\n",
      "Epoch 3/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 136885.0156 - mae: 100.3196 - val_loss: 134987.7969 - val_mae: 85.0524\n",
      "Epoch 4/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 67029.1797 - mae: 75.9677 - val_loss: 10494.1992 - val_mae: 60.0727\n",
      "Epoch 5/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10804.7178 - mae: 60.9958 - val_loss: 10243.0771 - val_mae: 58.1748\n",
      "Epoch 6/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9927.2949 - mae: 58.2135 - val_loss: 11196.7197 - val_mae: 61.5780\n",
      "Epoch 7/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10434.8291 - mae: 57.3179 - val_loss: 10497.3867 - val_mae: 54.5468\n",
      "Epoch 8/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9806.0654 - mae: 55.3277 - val_loss: 33475.3164 - val_mae: 57.9677\n",
      "Epoch 9/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 163061.1875 - mae: 61.4960 - val_loss: 9088.3340 - val_mae: 51.5476\n",
      "Epoch 10/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9281.4287 - mae: 50.8595 - val_loss: 30437.4961 - val_mae: 64.6182\n",
      "Epoch 11/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 46095.2422 - mae: 62.1148 - val_loss: 6913.5576 - val_mae: 43.3309\n",
      "Epoch 12/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6613.3276 - mae: 43.3420 - val_loss: 6547.9263 - val_mae: 42.7051\n",
      "Epoch 13/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6644.9722 - mae: 43.1199 - val_loss: 6382.9258 - val_mae: 39.2296\n",
      "Epoch 14/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5897.3818 - mae: 39.2882 - val_loss: 6371.3247 - val_mae: 43.0528\n",
      "Epoch 15/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6104.7803 - mae: 39.9187 - val_loss: 5645.1108 - val_mae: 37.7284\n",
      "Epoch 16/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6146.0996 - mae: 39.3810 - val_loss: 5812.3740 - val_mae: 40.1915\n",
      "Epoch 17/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5608.0127 - mae: 36.6542 - val_loss: 5850.3550 - val_mae: 37.4014\n",
      "Epoch 18/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5678.6479 - mae: 35.5283 - val_loss: 5633.1982 - val_mae: 36.3757\n",
      "Epoch 19/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5305.3447 - mae: 33.7907 - val_loss: 5263.2925 - val_mae: 35.6823\n",
      "Epoch 20/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5724.5654 - mae: 32.6415 - val_loss: 4503.3296 - val_mae: 31.3677\n",
      "Epoch 21/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 10423.8594 - mae: 32.3527 - val_loss: 4354.3516 - val_mae: 29.5668\n",
      "Epoch 22/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4310.2173 - mae: 29.6788 - val_loss: 4059.0945 - val_mae: 28.6568\n",
      "Epoch 23/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4534.8193 - mae: 29.9338 - val_loss: 6997.3960 - val_mae: 31.0325\n",
      "Epoch 24/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8046.0791 - mae: 28.7904 - val_loss: 3668.6775 - val_mae: 27.9484\n",
      "Epoch 25/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3549.0994 - mae: 27.8800 - val_loss: 3780.1736 - val_mae: 28.8985\n",
      "Epoch 26/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3603.8931 - mae: 27.0026 - val_loss: 2796.5151 - val_mae: 25.5191\n",
      "Epoch 27/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2937.3506 - mae: 25.4415 - val_loss: 2423.2144 - val_mae: 22.3930\n",
      "Epoch 28/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2670.5771 - mae: 24.1998 - val_loss: 2254.7000 - val_mae: 24.0527\n",
      "Epoch 29/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2158.8262 - mae: 22.4026 - val_loss: 2070.9922 - val_mae: 21.7135\n",
      "Epoch 30/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2114.2180 - mae: 22.0291 - val_loss: 1833.6444 - val_mae: 21.9009\n",
      "Epoch 31/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1978.1044 - mae: 21.6285 - val_loss: 1276.6324 - val_mae: 18.4825\n",
      "Epoch 32/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1521.9447 - mae: 19.5317 - val_loss: 1283.8209 - val_mae: 20.5723\n",
      "Epoch 33/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1485.6274 - mae: 19.2156 - val_loss: 1212.5592 - val_mae: 17.8793\n",
      "Epoch 34/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1425.9146 - mae: 18.4256 - val_loss: 1007.5616 - val_mae: 18.4600\n",
      "Epoch 35/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1315.3239 - mae: 18.6322 - val_loss: 1044.0371 - val_mae: 19.4789\n",
      "Epoch 36/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1168.4062 - mae: 18.2071 - val_loss: 929.6509 - val_mae: 18.1697\n",
      "Epoch 37/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1171.7825 - mae: 17.2177 - val_loss: 625.5894 - val_mae: 13.6273\n",
      "Epoch 38/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 962.7438 - mae: 15.6320 - val_loss: 990.4539 - val_mae: 16.1895\n",
      "Epoch 39/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1073.2014 - mae: 16.0238 - val_loss: 2002.6111 - val_mae: 23.8226\n",
      "Epoch 40/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2293.2361 - mae: 21.3833 - val_loss: 1073.8301 - val_mae: 16.0431\n",
      "Epoch 41/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 901.5819 - mae: 15.7026 - val_loss: 572.8511 - val_mae: 13.9624\n",
      "Epoch 42/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 785.2644 - mae: 14.8886 - val_loss: 570.9531 - val_mae: 13.6030\n",
      "Epoch 43/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 827.4052 - mae: 15.3452 - val_loss: 472.0504 - val_mae: 12.6060\n",
      "Epoch 44/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.9969 - mae: 14.0105 - val_loss: 478.6896 - val_mae: 11.5677\n",
      "Epoch 45/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 707.5172 - mae: 13.8559 - val_loss: 599.6291 - val_mae: 14.2622\n",
      "Epoch 46/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 546.7219 - mae: 13.5351 - val_loss: 1019.5436 - val_mae: 18.0610\n",
      "Epoch 47/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 686.4815 - mae: 14.0762 - val_loss: 1609.9667 - val_mae: 14.6542\n",
      "Epoch 48/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 849.9689 - mae: 13.9480 - val_loss: 991.2899 - val_mae: 19.8246\n",
      "Epoch 49/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 718.6355 - mae: 14.0406 - val_loss: 793.6315 - val_mae: 17.3698\n",
      "Epoch 50/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 743.6974 - mae: 14.2303 - val_loss: 317.4776 - val_mae: 10.8302\n",
      "Epoch 51/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 605.0751 - mae: 13.6839 - val_loss: 426.6779 - val_mae: 12.1060\n",
      "Epoch 52/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 463.4625 - mae: 12.2284 - val_loss: 2937.5151 - val_mae: 17.1172\n",
      "Epoch 53/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 803.9894 - mae: 13.7433 - val_loss: 463.1469 - val_mae: 12.4871\n",
      "Epoch 54/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 664.7964 - mae: 12.3307 - val_loss: 640.6003 - val_mae: 15.1767\n",
      "Epoch 55/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 596.1944 - mae: 13.5366 - val_loss: 525.2988 - val_mae: 15.1396\n",
      "Epoch 56/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 393.1397 - mae: 11.4622 - val_loss: 366.8271 - val_mae: 11.6230\n",
      "Epoch 57/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 548.0197 - mae: 11.4048 - val_loss: 247.1762 - val_mae: 9.1214\n",
      "Epoch 58/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 622.9396 - mae: 13.4178 - val_loss: 343.7193 - val_mae: 12.5924\n",
      "Epoch 59/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 466.8030 - mae: 11.9944 - val_loss: 379.5876 - val_mae: 10.8555\n",
      "Epoch 60/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 351.5680 - mae: 10.6365 - val_loss: 482.2607 - val_mae: 14.2606\n",
      "Epoch 61/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.1111 - mae: 13.5192 - val_loss: 493.9442 - val_mae: 13.6088\n",
      "Epoch 62/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 598.8191 - mae: 12.9802 - val_loss: 453.6538 - val_mae: 11.5182\n",
      "Epoch 63/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 452.4388 - mae: 12.4150 - val_loss: 445.0514 - val_mae: 12.6316\n",
      "Epoch 64/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 435.7068 - mae: 11.2086 - val_loss: 384.5616 - val_mae: 9.4640\n",
      "Epoch 65/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 367.1494 - mae: 10.5164 - val_loss: 283.7157 - val_mae: 10.2471\n",
      "Epoch 66/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 567.7905 - mae: 11.6227 - val_loss: 175.6687 - val_mae: 8.2658\n",
      "Epoch 67/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 393.3409 - mae: 10.9099 - val_loss: 314.3468 - val_mae: 10.2109\n",
      "Epoch 68/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 464.6788 - mae: 11.8066 - val_loss: 521.6063 - val_mae: 15.0147\n",
      "Epoch 69/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 607.5844 - mae: 12.1055 - val_loss: 212.0554 - val_mae: 8.9411\n",
      "Epoch 70/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 475.5222 - mae: 11.7708 - val_loss: 219.1420 - val_mae: 9.4011\n",
      "Epoch 71/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 276.5232 - mae: 9.5864 - val_loss: 383.9749 - val_mae: 11.9931\n",
      "Epoch 72/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 555.6635 - mae: 12.4405 - val_loss: 605.0557 - val_mae: 14.8447\n",
      "Epoch 73/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 614.7299 - mae: 13.5663 - val_loss: 280.7190 - val_mae: 10.1071\n",
      "Epoch 74/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 310.6847 - mae: 10.4500 - val_loss: 287.0277 - val_mae: 9.5827\n",
      "Epoch 75/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 288.4175 - mae: 10.2566 - val_loss: 310.3091 - val_mae: 10.9942\n",
      "Epoch 76/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 300.4423 - mae: 10.1208 - val_loss: 230.3199 - val_mae: 9.5430\n",
      "Epoch 77/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 396.0136 - mae: 9.7569 - val_loss: 264.0549 - val_mae: 9.4133\n",
      "Epoch 78/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 277.8620 - mae: 9.8258 - val_loss: 236.2473 - val_mae: 8.7519\n",
      "Epoch 79/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 334.7912 - mae: 10.1179 - val_loss: 317.0463 - val_mae: 9.6938\n",
      "Epoch 80/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 255.4035 - mae: 9.3685 - val_loss: 164.0011 - val_mae: 7.5338\n",
      "Epoch 81/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 257.3512 - mae: 9.5755 - val_loss: 167.4194 - val_mae: 8.0586\n",
      "Epoch 82/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 221.9333 - mae: 8.6081 - val_loss: 476.2254 - val_mae: 12.4014\n",
      "Epoch 83/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 444.4048 - mae: 11.2572 - val_loss: 207.9429 - val_mae: 8.4249\n",
      "Epoch 84/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 237.4763 - mae: 9.1296 - val_loss: 229.5613 - val_mae: 9.4574\n",
      "Epoch 85/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 218.6411 - mae: 8.9706 - val_loss: 151.3750 - val_mae: 7.7349\n",
      "Epoch 86/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 513.5994 - mae: 11.7404 - val_loss: 224.9341 - val_mae: 10.4873\n",
      "Epoch 87/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 166.2709 - mae: 7.8379 - val_loss: 153.3836 - val_mae: 7.3243\n",
      "Epoch 88/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 301.1026 - mae: 9.4409 - val_loss: 191.8683 - val_mae: 8.1360\n",
      "Epoch 89/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 203.2103 - mae: 8.7330 - val_loss: 212.5106 - val_mae: 8.7646\n",
      "Epoch 90/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 933.4267 - mae: 14.7273 - val_loss: 232.8303 - val_mae: 9.3590\n",
      "Epoch 91/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 193.2003 - mae: 8.5132 - val_loss: 687.3418 - val_mae: 14.5376\n",
      "Epoch 92/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 331.2218 - mae: 10.2045 - val_loss: 155.8551 - val_mae: 7.5632\n",
      "Epoch 93/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 197.3564 - mae: 8.3646 - val_loss: 232.2893 - val_mae: 10.2267\n",
      "Epoch 94/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 213.5565 - mae: 8.9419 - val_loss: 173.7850 - val_mae: 8.0361\n",
      "Epoch 95/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 208.9433 - mae: 8.4681 - val_loss: 506.2477 - val_mae: 14.1224\n",
      "Epoch 96/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1277.3359 - mae: 15.2457 - val_loss: 713.8621 - val_mae: 11.5629\n",
      "Epoch 97/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 516.5190 - mae: 11.0366 - val_loss: 310.6826 - val_mae: 10.8434\n",
      "Epoch 98/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1562.4534 - mae: 12.3234 - val_loss: 458.8085 - val_mae: 11.4426\n",
      "Epoch 99/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 334.0154 - mae: 10.0398 - val_loss: 211.6885 - val_mae: 8.2703\n",
      "Epoch 100/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 260.3322 - mae: 8.8389 - val_loss: 399.0681 - val_mae: 10.9213\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_dev, Y_dev),\n",
    "    epochs=100,              # Start with a small number, like 50\n",
    "    batch_size=32,          # Common choice\n",
    "    verbose=1               # Shows progress per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d60ec785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stockClosePrice</th>\n",
       "      <th>deltaT_years</th>\n",
       "      <th>riskfree_rate</th>\n",
       "      <th>isCall</th>\n",
       "      <th>volume</th>\n",
       "      <th>openInterest</th>\n",
       "      <th>impliedVolatility</th>\n",
       "      <th>inTheMoney</th>\n",
       "      <th>isNVDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.0</td>\n",
       "      <td>211.160004</td>\n",
       "      <td>0.690819</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8311.0</td>\n",
       "      <td>0.286323</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170.0</td>\n",
       "      <td>211.160004</td>\n",
       "      <td>0.191854</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>10702.0</td>\n",
       "      <td>0.334968</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.0</td>\n",
       "      <td>211.160004</td>\n",
       "      <td>1.189220</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.215431</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.0</td>\n",
       "      <td>212.440002</td>\n",
       "      <td>0.715615</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.594242</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>440.0</td>\n",
       "      <td>222.243881</td>\n",
       "      <td>1.975468</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>585.0</td>\n",
       "      <td>623.619995</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.210945</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>500.0</td>\n",
       "      <td>623.619995</td>\n",
       "      <td>0.268510</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>3951.0</td>\n",
       "      <td>11085.0</td>\n",
       "      <td>0.275581</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>695.0</td>\n",
       "      <td>620.679993</td>\n",
       "      <td>0.279512</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151864</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>410.0</td>\n",
       "      <td>624.059998</td>\n",
       "      <td>0.370344</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.367377</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>505.0</td>\n",
       "      <td>617.849976</td>\n",
       "      <td>0.107397</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2912 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      strike  stockClosePrice  deltaT_years  riskfree_rate  isCall  volume  \\\n",
       "0      175.0       211.160004      0.690819         0.0437       0     1.0   \n",
       "1      170.0       211.160004      0.191854         0.0437       0   636.0   \n",
       "2      240.0       211.160004      1.189220         0.0437       0     1.0   \n",
       "3      110.0       212.440002      0.715615         0.0433       1     3.0   \n",
       "4      440.0       222.243881      1.975468         0.0445       0     8.0   \n",
       "...      ...              ...           ...            ...     ...     ...   \n",
       "2907   585.0       623.619995      0.016439         0.0437       0    61.0   \n",
       "2908   500.0       623.619995      0.268510         0.0437       0  3951.0   \n",
       "2909   695.0       620.679993      0.279512         0.0437       0     1.0   \n",
       "2910   410.0       624.059998      0.370344         0.0436       0    17.0   \n",
       "2911   505.0       617.849976      0.107397         0.0428       1     0.0   \n",
       "\n",
       "      openInterest  impliedVolatility  inTheMoney  isNVDA  \n",
       "0           8311.0           0.286323       False       0  \n",
       "1          10702.0           0.334968       False       0  \n",
       "2             12.0           0.215431        True       0  \n",
       "3             24.0           0.594242        True       0  \n",
       "4              0.0           0.000010        True       0  \n",
       "...            ...                ...         ...     ...  \n",
       "2907          78.0           0.210945       False       0  \n",
       "2908       11085.0           0.275581       False       0  \n",
       "2909           0.0           0.151864        True       0  \n",
       "2910         286.0           0.367377       False       0  \n",
       "2911           1.0           0.553532        True       0  \n",
       "\n",
       "[2912 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.concat([X_test,Y_test])\n",
    "X_test\n",
    "# Y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
