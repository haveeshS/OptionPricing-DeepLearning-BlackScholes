{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df8f7476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "options_df = pd.read_csv(\"options_cleaned.csv\")\n",
    "\n",
    "# options_df.sample(frac=1, random_state=43)\n",
    "full_options_df = pd.read_csv(\"options_withriskfreerates_andDeltaT.csv\")\n",
    "\n",
    "options_df[\"stockTicker\"] = full_options_df[\"stockTicker\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52fae1",
   "metadata": {},
   "source": [
    "Need to prepare the train, validation/dev and test sets. In this first trial, I will use a 70%/20%/10% split\n",
    "\n",
    "I will also perform this split individually for each stock ticker, in order to have equal portions from each stock ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4af5a300",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\_core\\fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "tickers = [\"AAPL\",\"NVDA\",\"TSLA\",\"AMD\",\"AMZN\",\"MSFT\",\"META\",\"SPY\"]\n",
    "\n",
    "train_list = []\n",
    "dev_list = []\n",
    "test_list = []\n",
    "\n",
    "for ticker in tickers:\n",
    "\n",
    "    df = options_df[full_options_df[\"stockTicker\"] == ticker]\n",
    "\n",
    "    train, dev, test = np.split(df.sample(frac=1,random_state=42), \n",
    "                       [int(0.7*len(df)), int(.9*len(df))])\n",
    "    \n",
    "    train_list.append(train)\n",
    "    dev_list.append(dev)\n",
    "    test_list.append(test)\n",
    "\n",
    "train_df = pd.concat(train_list, ignore_index=True)\n",
    "dev_df = pd.concat(dev_list, ignore_index=True)\n",
    "test_df = pd.concat(test_list, ignore_index=True)\n",
    "\n",
    "target_col = \"lastPrice\"\n",
    "ticker_col = \"stockTicker\"\n",
    "\n",
    "Y_train = train_df[[target_col]]\n",
    "X_train = train_df.drop(columns=[target_col, ticker_col])  \n",
    "\n",
    "Y_dev = dev_df[[target_col]]\n",
    "X_dev = dev_df.drop(columns=[target_col, ticker_col]) \n",
    "\n",
    "test_df.to_csv(\"test_data_options.csv\",index=False)\n",
    "\n",
    "Y_test = test_df[[target_col]]\n",
    "X_test = test_df.drop(columns=[target_col, ticker_col]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "362ed5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_dev_scaled = scaler.transform(X_dev)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3034b0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit Input layer\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0546640a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(learning_rate=0.0005)  \n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db4903d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttributeError: module 'ml_dtypes' has no attribute 'float4_e2m1fn'\n",
      "Epoch 1/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 17174.7402 - mae: 70.6064 - val_loss: 8312.2080 - val_mae: 49.7640\n",
      "Epoch 2/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 7021.2568 - mae: 46.1908 - val_loss: 3963.1978 - val_mae: 38.3412\n",
      "Epoch 3/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 2966.7932 - mae: 32.3207 - val_loss: 1272.7242 - val_mae: 21.4469\n",
      "Epoch 4/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 1134.0239 - mae: 19.6021 - val_loss: 722.2285 - val_mae: 15.5868\n",
      "Epoch 5/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 695.1835 - mae: 15.1732 - val_loss: 580.5781 - val_mae: 12.9262\n",
      "Epoch 6/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 569.4140 - mae: 12.7449 - val_loss: 467.9598 - val_mae: 11.6186\n",
      "Epoch 7/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 485.2159 - mae: 11.2421 - val_loss: 393.7627 - val_mae: 10.0282\n",
      "Epoch 8/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 426.5760 - mae: 10.1042 - val_loss: 354.1188 - val_mae: 9.3397\n",
      "Epoch 9/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 365.3398 - mae: 9.5274 - val_loss: 324.9415 - val_mae: 8.9231\n",
      "Epoch 10/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 343.4040 - mae: 9.1968 - val_loss: 302.4566 - val_mae: 8.2365\n",
      "Epoch 11/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 345.1660 - mae: 8.9630 - val_loss: 301.2500 - val_mae: 8.5306\n",
      "Epoch 12/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 344.7925 - mae: 8.7089 - val_loss: 293.1328 - val_mae: 8.1489\n",
      "Epoch 13/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 313.3564 - mae: 8.3058 - val_loss: 277.6799 - val_mae: 7.6073\n",
      "Epoch 14/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 309.2141 - mae: 8.1835 - val_loss: 301.0296 - val_mae: 8.0074\n",
      "Epoch 15/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 287.3285 - mae: 7.8664 - val_loss: 260.9383 - val_mae: 7.3945\n",
      "Epoch 16/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 296.9424 - mae: 7.8469 - val_loss: 282.2058 - val_mae: 8.0266\n",
      "Epoch 17/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 258.1065 - mae: 7.6866 - val_loss: 255.1258 - val_mae: 7.4323\n",
      "Epoch 18/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 329.1745 - mae: 8.0215 - val_loss: 256.6003 - val_mae: 7.3843\n",
      "Epoch 19/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 287.1002 - mae: 7.5590 - val_loss: 296.9356 - val_mae: 9.2796\n",
      "Epoch 20/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 264.7118 - mae: 7.7426 - val_loss: 244.3848 - val_mae: 7.1532\n",
      "Epoch 21/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 233.8376 - mae: 7.1717 - val_loss: 236.0789 - val_mae: 6.9680\n",
      "Epoch 22/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 265.7518 - mae: 7.2749 - val_loss: 331.0806 - val_mae: 8.9946\n",
      "Epoch 23/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 290.3911 - mae: 7.4923 - val_loss: 247.7376 - val_mae: 7.3948\n",
      "Epoch 24/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 233.9164 - mae: 6.8632 - val_loss: 276.2429 - val_mae: 7.5739\n",
      "Epoch 25/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 236.2942 - mae: 6.8528 - val_loss: 442.9218 - val_mae: 9.3007\n",
      "Epoch 26/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 259.5596 - mae: 7.2678 - val_loss: 229.3937 - val_mae: 7.0200\n",
      "Epoch 27/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 276.2780 - mae: 6.9938 - val_loss: 217.7309 - val_mae: 6.7288\n",
      "Epoch 28/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 229.9147 - mae: 6.9074 - val_loss: 274.7534 - val_mae: 7.9190\n",
      "Epoch 29/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 275.8746 - mae: 7.0842 - val_loss: 244.9497 - val_mae: 6.7792\n",
      "Epoch 30/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 258.8246 - mae: 6.8709 - val_loss: 233.3949 - val_mae: 6.5915\n",
      "Epoch 31/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 240.8718 - mae: 6.6778 - val_loss: 296.6475 - val_mae: 8.2046\n",
      "Epoch 32/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 218.9256 - mae: 6.6344 - val_loss: 202.5978 - val_mae: 6.0279\n",
      "Epoch 33/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 239.3570 - mae: 6.7446 - val_loss: 327.4407 - val_mae: 7.4430\n",
      "Epoch 34/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 259.3506 - mae: 6.7181 - val_loss: 240.8956 - val_mae: 6.9276\n",
      "Epoch 35/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 263.2428 - mae: 6.8791 - val_loss: 225.2987 - val_mae: 6.7461\n",
      "Epoch 36/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 228.9813 - mae: 6.3760 - val_loss: 201.9798 - val_mae: 6.1511\n",
      "Epoch 37/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 238.3302 - mae: 6.6563 - val_loss: 209.9489 - val_mae: 6.1253\n",
      "Epoch 38/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 221.3615 - mae: 6.3126 - val_loss: 209.4462 - val_mae: 6.4612\n",
      "Epoch 39/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 206.5132 - mae: 6.0973 - val_loss: 231.5292 - val_mae: 6.6657\n",
      "Epoch 40/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 238.1679 - mae: 6.4064 - val_loss: 194.5250 - val_mae: 6.2170\n",
      "Epoch 41/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 213.0413 - mae: 6.1698 - val_loss: 221.0902 - val_mae: 6.2707\n",
      "Epoch 42/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 229.3725 - mae: 6.0579 - val_loss: 192.9153 - val_mae: 5.7968\n",
      "Epoch 43/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 209.1393 - mae: 5.9419 - val_loss: 201.1561 - val_mae: 5.7786\n",
      "Epoch 44/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 204.2626 - mae: 5.9626 - val_loss: 197.4706 - val_mae: 5.9287\n",
      "Epoch 45/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 203.7066 - mae: 5.7905 - val_loss: 190.7554 - val_mae: 5.6079\n",
      "Epoch 46/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 217.2254 - mae: 6.1380 - val_loss: 187.7846 - val_mae: 5.7618\n",
      "Epoch 47/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 252.1205 - mae: 6.0183 - val_loss: 199.4579 - val_mae: 5.7119\n",
      "Epoch 48/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 263.9427 - mae: 6.0884 - val_loss: 230.8804 - val_mae: 6.8952\n",
      "Epoch 49/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - loss: 208.3589 - mae: 5.9267 - val_loss: 260.6693 - val_mae: 6.9066\n",
      "Epoch 50/50\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 197.0103 - mae: 5.9133 - val_loss: 176.7452 - val_mae: 5.2567\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train_scaled, Y_train,\n",
    "    validation_data=(X_dev_scaled, Y_dev),\n",
    "    epochs=50,              # Start with a small number, like 50\n",
    "    batch_size=32,          # Common choice\n",
    "    verbose=1               # Shows progress per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e87c0519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 385.7964 - mae: 6.6158\n",
      "Test MAE: 5.30\n"
     ]
    }
   ],
   "source": [
    "loss, mae = model.evaluate(X_test_scaled, Y_test)\n",
    "print(f\"Test MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "984b3623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiha\\AppData\\Local\\Temp\\ipykernel_13796\\3135563355.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-1.04627395 -1.04627395 -1.04627395 ... -1.04627395 -1.04627395\n",
      "  0.95577263]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_df_scaled.iloc[:,i] = X_test_scaled[:,i]\n",
      "C:\\Users\\saiha\\AppData\\Local\\Temp\\ipykernel_13796\\3135563355.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.92023038 -0.92023038  1.0866844  ...  1.0866844  -0.92023038\n",
      "  1.0866844 ]' has dtype incompatible with bool, please explicitly cast to a compatible dtype first.\n",
      "  test_df_scaled.iloc[:,i] = X_test_scaled[:,i]\n",
      "C:\\Users\\saiha\\AppData\\Local\\Temp\\ipykernel_13796\\3135563355.py:5: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[-0.47635178 -0.47635178 -0.47635178 ... -0.47635178 -0.47635178\n",
      " -0.47635178]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  test_df_scaled.iloc[:,i] = X_test_scaled[:,i]\n"
     ]
    }
   ],
   "source": [
    "test_df_scaled = test_df\n",
    "\n",
    "for i in range(X_test_scaled.shape[1]):\n",
    "\n",
    "    test_df_scaled.iloc[:,i] = X_test_scaled[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bceeb781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.74368847e-01, -8.83167727e-01, -1.41368372e-02, ...,\n",
       "        -3.45556176e-01, -9.20230382e-01, -4.76351782e-01],\n",
       "       [-7.89693514e-01, -8.83167727e-01, -7.29054850e-01, ...,\n",
       "        -2.82715354e-01, -9.20230382e-01, -4.76351782e-01],\n",
       "       [-5.75148178e-01, -8.83167727e-01,  6.99973362e-01, ...,\n",
       "        -4.37136622e-01,  1.08668440e+00, -4.76351782e-01],\n",
       "       ...,\n",
       "       [ 8.19396501e-01,  9.81202196e-01, -6.03457406e-01, ...,\n",
       "        -5.19255463e-01,  1.08668440e+00, -4.76351782e-01],\n",
       "       [-5.41095070e-02,  9.96589917e-01, -4.73313670e-01, ...,\n",
       "        -2.40847755e-01, -9.20230382e-01, -4.76351782e-01],\n",
       "       [ 2.37059162e-01,  9.68318334e-01, -8.50064885e-01, ...,\n",
       "        -3.65310798e-04,  1.08668440e+00, -4.76351782e-01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62cc0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_scaled.to_csv(\"test_data_options_scaled.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e044c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 290.4188 - mae: 5.4270\n",
      "Test MAE: 4.13\n"
     ]
    }
   ],
   "source": [
    "Y_test_new = test_df_scaled[[target_col]]\n",
    "X_test_scaled_new = test_df_scaled.drop(columns=[target_col, ticker_col]) \n",
    "\n",
    "loss, mae = model.evaluate(X_test_scaled_new, Y_test_new)\n",
    "print(f\"Test MAE: {mae:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4e5d25da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mae', 'val_loss', 'val_mae'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b3a0944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(0.0005)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.optimizer.learning_rate.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87544f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.yscale(\"log\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"Evolution of the loss function with scaled features\")\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b8bb7713",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_scaledfeatures.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec23e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "55ccccf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strike</th>\n",
       "      <th>stockClosePrice</th>\n",
       "      <th>deltaT_years</th>\n",
       "      <th>riskfree_rate</th>\n",
       "      <th>isCall</th>\n",
       "      <th>volume</th>\n",
       "      <th>openInterest</th>\n",
       "      <th>impliedVolatility</th>\n",
       "      <th>inTheMoney</th>\n",
       "      <th>isNVDA</th>\n",
       "      <th>lastPrice</th>\n",
       "      <th>stockTicker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175.0</td>\n",
       "      <td>211.160004</td>\n",
       "      <td>0.690819</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8311.0</td>\n",
       "      <td>0.286323</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5.58</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>170.0</td>\n",
       "      <td>211.160004</td>\n",
       "      <td>0.191854</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>636.0</td>\n",
       "      <td>10702.0</td>\n",
       "      <td>0.334968</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>240.0</td>\n",
       "      <td>211.160004</td>\n",
       "      <td>1.189220</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.215431</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>36.43</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>110.0</td>\n",
       "      <td>212.440002</td>\n",
       "      <td>0.715615</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.594242</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>105.15</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>440.0</td>\n",
       "      <td>222.243881</td>\n",
       "      <td>1.975468</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>217.25</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>585.0</td>\n",
       "      <td>623.619995</td>\n",
       "      <td>0.016439</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.210945</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>500.0</td>\n",
       "      <td>623.619995</td>\n",
       "      <td>0.268510</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>3951.0</td>\n",
       "      <td>11085.0</td>\n",
       "      <td>0.275581</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>2.11</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>695.0</td>\n",
       "      <td>620.679993</td>\n",
       "      <td>0.279512</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.151864</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>75.39</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>410.0</td>\n",
       "      <td>624.059998</td>\n",
       "      <td>0.370344</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>0.367377</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>505.0</td>\n",
       "      <td>617.849976</td>\n",
       "      <td>0.107397</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.553532</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>114.48</td>\n",
       "      <td>SPY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2912 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      strike  stockClosePrice  deltaT_years  riskfree_rate  isCall  volume  \\\n",
       "0      175.0       211.160004      0.690819         0.0437       0     1.0   \n",
       "1      170.0       211.160004      0.191854         0.0437       0   636.0   \n",
       "2      240.0       211.160004      1.189220         0.0437       0     1.0   \n",
       "3      110.0       212.440002      0.715615         0.0433       1     3.0   \n",
       "4      440.0       222.243881      1.975468         0.0445       0     8.0   \n",
       "...      ...              ...           ...            ...     ...     ...   \n",
       "2907   585.0       623.619995      0.016439         0.0437       0    61.0   \n",
       "2908   500.0       623.619995      0.268510         0.0437       0  3951.0   \n",
       "2909   695.0       620.679993      0.279512         0.0437       0     1.0   \n",
       "2910   410.0       624.059998      0.370344         0.0436       0    17.0   \n",
       "2911   505.0       617.849976      0.107397         0.0428       1     0.0   \n",
       "\n",
       "      openInterest  impliedVolatility  inTheMoney  isNVDA  lastPrice  \\\n",
       "0           8311.0           0.286323       False       0       5.58   \n",
       "1          10702.0           0.334968       False       0       0.87   \n",
       "2             12.0           0.215431        True       0      36.43   \n",
       "3             24.0           0.594242        True       0     105.15   \n",
       "4              0.0           0.000010        True       0     217.25   \n",
       "...            ...                ...         ...     ...        ...   \n",
       "2907          78.0           0.210945       False       0       0.09   \n",
       "2908       11085.0           0.275581       False       0       2.11   \n",
       "2909           0.0           0.151864        True       0      75.39   \n",
       "2910         286.0           0.367377       False       0       1.23   \n",
       "2911           1.0           0.553532        True       0     114.48   \n",
       "\n",
       "     stockTicker  \n",
       "0           AAPL  \n",
       "1           AAPL  \n",
       "2           AAPL  \n",
       "3           AAPL  \n",
       "4           AAPL  \n",
       "...          ...  \n",
       "2907         SPY  \n",
       "2908         SPY  \n",
       "2909         SPY  \n",
       "2910         SPY  \n",
       "2911         SPY  \n",
       "\n",
       "[2912 rows x 12 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1474431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.507769584655762, 13.244246482849121)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history[\"mae\"][-1],history.history[\"val_mae\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41790b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import BlackScholesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e50e343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_price = options_df[\"stockClosePrice\"]\n",
    "strike_price = options_df[\"strike\"]\n",
    "riskfree_rate = options_df[\"riskfree_rate\"]\n",
    "time_to_expiry = options_df[\"deltaT_years\"]\n",
    "volatility = options_df[\"impliedVolatility\"]\n",
    "isCall = options_df[\"isCall\"]\n",
    "\n",
    "price_BS = np.zeros_like(stock_price)\n",
    "\n",
    "for i in range(len(options_df)):\n",
    "    price_BS[i] = BlackScholesModel(stock_price[i],strike_price[i],riskfree_rate[i],time_to_expiry[i],volatility[i],isCall[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208b3be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(29.591169294508173)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_BS = np.mean(np.abs(price_BS - options_df[\"lastPrice\"]))\n",
    "\n",
    "mae_BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bea4facd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(80.99049724896837), np.float64(135.43975112824418))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "options_df[\"lastPrice\"].mean(), options_df[\"lastPrice\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "14f67d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    for i in range(hp.Int(\"num_layers\", 1, 3)):\n",
    "        model.add(\n",
    "            layers.Dense(\n",
    "                units=hp.Int(f\"units_{i}\", 32, 256, step=32),\n",
    "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "    # Explicit mapping to avoid any naming issues\n",
    "    optimizer_name = hp.Choice(\"optimizer\", [\"adam\", \"rmsprop\", \"sgd\"])\n",
    "    learning_rate = hp.Float(\"learning_rate\", 1e-4, 1e-2, sampling=\"log\")\n",
    "\n",
    "    optimizer_classes = {\n",
    "        \"adam\": keras.optimizers.Adam,\n",
    "        \"rmsprop\": keras.optimizers.RMSprop,\n",
    "        \"sgd\": keras.optimizers.SGD\n",
    "    }\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=optimizer_classes[optimizer_name](learning_rate=learning_rate),\n",
    "        loss=\"mae\",\n",
    "        metrics=[\"mae\"]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fda0064d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from kt_tuner\\option_price_model\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective=\"val_mae\",\n",
    "    max_trials=25,              # Try 10 different hyperparameter combinations\n",
    "    executions_per_trial=1,     # How many times to train each model\n",
    "    directory=\"kt_tuner\",\n",
    "    project_name=\"option_price_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a52aafde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 25 Complete [00h 00m 42s]\n",
      "val_mae: 69.79572296142578\n",
      "\n",
      "Best val_mae So Far: 7.587751388549805\n",
      "Total elapsed time: 01h 13m 21s\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "tuner.search(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_dev, Y_dev),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb56cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow.keras.optimizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1445b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saiha\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\saving\\saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 2 variables whereas the saved optimizer has 18 variables. \n",
      "  saveable.load_own_variables(weights_store.get(inner_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 32\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "learning_rate: 0.0009388837297496945\n",
      "units_1: 128\n",
      "units_2: 64\n",
      "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9.1134 - mae: 9.1134\n",
      "Test MAE: 7.897063255310059\n"
     ]
    }
   ],
   "source": [
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "best_hp = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(\"Best hyperparameters:\")\n",
    "for param in best_hp.values:\n",
    "    print(f\"{param}: {best_hp.get(param)}\")\n",
    "\n",
    "# Evaluate the best model\n",
    "test_loss, test_mae = best_model.evaluate(X_test, Y_test)\n",
    "print(\"Test MAE:\", test_mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0188d9e1",
   "metadata": {},
   "source": [
    "After tuning and finding the best hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb5fecf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save(\"best_model_from_tuner.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd2d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Explicit Input layer\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1)  # Regression output\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5995019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0009)  \n",
    "\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "884c6836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - loss: 615095.3125 - mae: 116.2965 - val_loss: 13190.6465 - val_mae: 66.7566\n",
      "Epoch 2/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 20778.9297 - mae: 73.5029 - val_loss: 76294.9453 - val_mae: 98.9629\n",
      "Epoch 3/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 136885.0156 - mae: 100.3196 - val_loss: 134987.7969 - val_mae: 85.0524\n",
      "Epoch 4/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 67029.1797 - mae: 75.9677 - val_loss: 10494.1992 - val_mae: 60.0727\n",
      "Epoch 5/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10804.7178 - mae: 60.9958 - val_loss: 10243.0771 - val_mae: 58.1748\n",
      "Epoch 6/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 9927.2949 - mae: 58.2135 - val_loss: 11196.7197 - val_mae: 61.5780\n",
      "Epoch 7/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 10434.8291 - mae: 57.3179 - val_loss: 10497.3867 - val_mae: 54.5468\n",
      "Epoch 8/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9806.0654 - mae: 55.3277 - val_loss: 33475.3164 - val_mae: 57.9677\n",
      "Epoch 9/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 163061.1875 - mae: 61.4960 - val_loss: 9088.3340 - val_mae: 51.5476\n",
      "Epoch 10/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 9281.4287 - mae: 50.8595 - val_loss: 30437.4961 - val_mae: 64.6182\n",
      "Epoch 11/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - loss: 46095.2422 - mae: 62.1148 - val_loss: 6913.5576 - val_mae: 43.3309\n",
      "Epoch 12/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6613.3276 - mae: 43.3420 - val_loss: 6547.9263 - val_mae: 42.7051\n",
      "Epoch 13/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6644.9722 - mae: 43.1199 - val_loss: 6382.9258 - val_mae: 39.2296\n",
      "Epoch 14/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5897.3818 - mae: 39.2882 - val_loss: 6371.3247 - val_mae: 43.0528\n",
      "Epoch 15/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6104.7803 - mae: 39.9187 - val_loss: 5645.1108 - val_mae: 37.7284\n",
      "Epoch 16/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 6146.0996 - mae: 39.3810 - val_loss: 5812.3740 - val_mae: 40.1915\n",
      "Epoch 17/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5608.0127 - mae: 36.6542 - val_loss: 5850.3550 - val_mae: 37.4014\n",
      "Epoch 18/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5678.6479 - mae: 35.5283 - val_loss: 5633.1982 - val_mae: 36.3757\n",
      "Epoch 19/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5305.3447 - mae: 33.7907 - val_loss: 5263.2925 - val_mae: 35.6823\n",
      "Epoch 20/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 5724.5654 - mae: 32.6415 - val_loss: 4503.3296 - val_mae: 31.3677\n",
      "Epoch 21/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 10423.8594 - mae: 32.3527 - val_loss: 4354.3516 - val_mae: 29.5668\n",
      "Epoch 22/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4310.2173 - mae: 29.6788 - val_loss: 4059.0945 - val_mae: 28.6568\n",
      "Epoch 23/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 4534.8193 - mae: 29.9338 - val_loss: 6997.3960 - val_mae: 31.0325\n",
      "Epoch 24/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 8046.0791 - mae: 28.7904 - val_loss: 3668.6775 - val_mae: 27.9484\n",
      "Epoch 25/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3549.0994 - mae: 27.8800 - val_loss: 3780.1736 - val_mae: 28.8985\n",
      "Epoch 26/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 3603.8931 - mae: 27.0026 - val_loss: 2796.5151 - val_mae: 25.5191\n",
      "Epoch 27/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2937.3506 - mae: 25.4415 - val_loss: 2423.2144 - val_mae: 22.3930\n",
      "Epoch 28/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2670.5771 - mae: 24.1998 - val_loss: 2254.7000 - val_mae: 24.0527\n",
      "Epoch 29/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2158.8262 - mae: 22.4026 - val_loss: 2070.9922 - val_mae: 21.7135\n",
      "Epoch 30/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2114.2180 - mae: 22.0291 - val_loss: 1833.6444 - val_mae: 21.9009\n",
      "Epoch 31/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1978.1044 - mae: 21.6285 - val_loss: 1276.6324 - val_mae: 18.4825\n",
      "Epoch 32/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1521.9447 - mae: 19.5317 - val_loss: 1283.8209 - val_mae: 20.5723\n",
      "Epoch 33/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1485.6274 - mae: 19.2156 - val_loss: 1212.5592 - val_mae: 17.8793\n",
      "Epoch 34/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1425.9146 - mae: 18.4256 - val_loss: 1007.5616 - val_mae: 18.4600\n",
      "Epoch 35/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1315.3239 - mae: 18.6322 - val_loss: 1044.0371 - val_mae: 19.4789\n",
      "Epoch 36/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1168.4062 - mae: 18.2071 - val_loss: 929.6509 - val_mae: 18.1697\n",
      "Epoch 37/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1171.7825 - mae: 17.2177 - val_loss: 625.5894 - val_mae: 13.6273\n",
      "Epoch 38/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 962.7438 - mae: 15.6320 - val_loss: 990.4539 - val_mae: 16.1895\n",
      "Epoch 39/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 1073.2014 - mae: 16.0238 - val_loss: 2002.6111 - val_mae: 23.8226\n",
      "Epoch 40/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2293.2361 - mae: 21.3833 - val_loss: 1073.8301 - val_mae: 16.0431\n",
      "Epoch 41/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 901.5819 - mae: 15.7026 - val_loss: 572.8511 - val_mae: 13.9624\n",
      "Epoch 42/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 785.2644 - mae: 14.8886 - val_loss: 570.9531 - val_mae: 13.6030\n",
      "Epoch 43/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 827.4052 - mae: 15.3452 - val_loss: 472.0504 - val_mae: 12.6060\n",
      "Epoch 44/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 648.9969 - mae: 14.0105 - val_loss: 478.6896 - val_mae: 11.5677\n",
      "Epoch 45/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 707.5172 - mae: 13.8559 - val_loss: 599.6291 - val_mae: 14.2622\n",
      "Epoch 46/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 546.7219 - mae: 13.5351 - val_loss: 1019.5436 - val_mae: 18.0610\n",
      "Epoch 47/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 686.4815 - mae: 14.0762 - val_loss: 1609.9667 - val_mae: 14.6542\n",
      "Epoch 48/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 849.9689 - mae: 13.9480 - val_loss: 991.2899 - val_mae: 19.8246\n",
      "Epoch 49/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 718.6355 - mae: 14.0406 - val_loss: 793.6315 - val_mae: 17.3698\n",
      "Epoch 50/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 743.6974 - mae: 14.2303 - val_loss: 317.4776 - val_mae: 10.8302\n",
      "Epoch 51/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 605.0751 - mae: 13.6839 - val_loss: 426.6779 - val_mae: 12.1060\n",
      "Epoch 52/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 463.4625 - mae: 12.2284 - val_loss: 2937.5151 - val_mae: 17.1172\n",
      "Epoch 53/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 803.9894 - mae: 13.7433 - val_loss: 463.1469 - val_mae: 12.4871\n",
      "Epoch 54/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 664.7964 - mae: 12.3307 - val_loss: 640.6003 - val_mae: 15.1767\n",
      "Epoch 55/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 596.1944 - mae: 13.5366 - val_loss: 525.2988 - val_mae: 15.1396\n",
      "Epoch 56/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 393.1397 - mae: 11.4622 - val_loss: 366.8271 - val_mae: 11.6230\n",
      "Epoch 57/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 548.0197 - mae: 11.4048 - val_loss: 247.1762 - val_mae: 9.1214\n",
      "Epoch 58/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 622.9396 - mae: 13.4178 - val_loss: 343.7193 - val_mae: 12.5924\n",
      "Epoch 59/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 466.8030 - mae: 11.9944 - val_loss: 379.5876 - val_mae: 10.8555\n",
      "Epoch 60/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 351.5680 - mae: 10.6365 - val_loss: 482.2607 - val_mae: 14.2606\n",
      "Epoch 61/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 639.1111 - mae: 13.5192 - val_loss: 493.9442 - val_mae: 13.6088\n",
      "Epoch 62/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 598.8191 - mae: 12.9802 - val_loss: 453.6538 - val_mae: 11.5182\n",
      "Epoch 63/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 452.4388 - mae: 12.4150 - val_loss: 445.0514 - val_mae: 12.6316\n",
      "Epoch 64/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 435.7068 - mae: 11.2086 - val_loss: 384.5616 - val_mae: 9.4640\n",
      "Epoch 65/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 367.1494 - mae: 10.5164 - val_loss: 283.7157 - val_mae: 10.2471\n",
      "Epoch 66/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 567.7905 - mae: 11.6227 - val_loss: 175.6687 - val_mae: 8.2658\n",
      "Epoch 67/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 393.3409 - mae: 10.9099 - val_loss: 314.3468 - val_mae: 10.2109\n",
      "Epoch 68/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 464.6788 - mae: 11.8066 - val_loss: 521.6063 - val_mae: 15.0147\n",
      "Epoch 69/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 607.5844 - mae: 12.1055 - val_loss: 212.0554 - val_mae: 8.9411\n",
      "Epoch 70/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 475.5222 - mae: 11.7708 - val_loss: 219.1420 - val_mae: 9.4011\n",
      "Epoch 71/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 276.5232 - mae: 9.5864 - val_loss: 383.9749 - val_mae: 11.9931\n",
      "Epoch 72/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 555.6635 - mae: 12.4405 - val_loss: 605.0557 - val_mae: 14.8447\n",
      "Epoch 73/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 614.7299 - mae: 13.5663 - val_loss: 280.7190 - val_mae: 10.1071\n",
      "Epoch 74/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 310.6847 - mae: 10.4500 - val_loss: 287.0277 - val_mae: 9.5827\n",
      "Epoch 75/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 288.4175 - mae: 10.2566 - val_loss: 310.3091 - val_mae: 10.9942\n",
      "Epoch 76/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 300.4423 - mae: 10.1208 - val_loss: 230.3199 - val_mae: 9.5430\n",
      "Epoch 77/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 396.0136 - mae: 9.7569 - val_loss: 264.0549 - val_mae: 9.4133\n",
      "Epoch 78/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 277.8620 - mae: 9.8258 - val_loss: 236.2473 - val_mae: 8.7519\n",
      "Epoch 79/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 334.7912 - mae: 10.1179 - val_loss: 317.0463 - val_mae: 9.6938\n",
      "Epoch 80/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 255.4035 - mae: 9.3685 - val_loss: 164.0011 - val_mae: 7.5338\n",
      "Epoch 81/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 257.3512 - mae: 9.5755 - val_loss: 167.4194 - val_mae: 8.0586\n",
      "Epoch 82/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 221.9333 - mae: 8.6081 - val_loss: 476.2254 - val_mae: 12.4014\n",
      "Epoch 83/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 444.4048 - mae: 11.2572 - val_loss: 207.9429 - val_mae: 8.4249\n",
      "Epoch 84/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 237.4763 - mae: 9.1296 - val_loss: 229.5613 - val_mae: 9.4574\n",
      "Epoch 85/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 218.6411 - mae: 8.9706 - val_loss: 151.3750 - val_mae: 7.7349\n",
      "Epoch 86/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 513.5994 - mae: 11.7404 - val_loss: 224.9341 - val_mae: 10.4873\n",
      "Epoch 87/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 166.2709 - mae: 7.8379 - val_loss: 153.3836 - val_mae: 7.3243\n",
      "Epoch 88/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 301.1026 - mae: 9.4409 - val_loss: 191.8683 - val_mae: 8.1360\n",
      "Epoch 89/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 203.2103 - mae: 8.7330 - val_loss: 212.5106 - val_mae: 8.7646\n",
      "Epoch 90/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 933.4267 - mae: 14.7273 - val_loss: 232.8303 - val_mae: 9.3590\n",
      "Epoch 91/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 193.2003 - mae: 8.5132 - val_loss: 687.3418 - val_mae: 14.5376\n",
      "Epoch 92/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 331.2218 - mae: 10.2045 - val_loss: 155.8551 - val_mae: 7.5632\n",
      "Epoch 93/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 197.3564 - mae: 8.3646 - val_loss: 232.2893 - val_mae: 10.2267\n",
      "Epoch 94/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 213.5565 - mae: 8.9419 - val_loss: 173.7850 - val_mae: 8.0361\n",
      "Epoch 95/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 208.9433 - mae: 8.4681 - val_loss: 506.2477 - val_mae: 14.1224\n",
      "Epoch 96/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1277.3359 - mae: 15.2457 - val_loss: 713.8621 - val_mae: 11.5629\n",
      "Epoch 97/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 516.5190 - mae: 11.0366 - val_loss: 310.6826 - val_mae: 10.8434\n",
      "Epoch 98/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 1562.4534 - mae: 12.3234 - val_loss: 458.8085 - val_mae: 11.4426\n",
      "Epoch 99/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 334.0154 - mae: 10.0398 - val_loss: 211.6885 - val_mae: 8.2703\n",
      "Epoch 100/100\n",
      "\u001b[1m636/636\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 260.3322 - mae: 8.8389 - val_loss: 399.0681 - val_mae: 10.9213\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_dev, Y_dev),\n",
    "    epochs=100,              # Start with a small number, like 50\n",
    "    batch_size=32,          # Common choice\n",
    "    verbose=1               # Shows progress per epoch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d60ec785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lastPrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>217.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>75.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>114.48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2912 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lastPrice\n",
       "0          5.58\n",
       "1          0.87\n",
       "2         36.43\n",
       "3        105.15\n",
       "4        217.25\n",
       "...         ...\n",
       "2907       0.09\n",
       "2908       2.11\n",
       "2909      75.39\n",
       "2910       1.23\n",
       "2911     114.48\n",
       "\n",
       "[2912 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pd.concat([X_test,Y_test])\n",
    "# X_test\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d325270f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[\"lastPrice\"] = Y_test[\"lastPrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a12a8b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv(\"test_data_options.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
